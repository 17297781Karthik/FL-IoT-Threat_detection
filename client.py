import osimport torchimport loggingimport numpy as npimport pandas as pdfrom typing import Dict, List, Tuplefrom collections import OrderedDictimport argparseimport flwr as flfrom flwr.common import NDArrays, FitIns, EvaluateIns, FitRes, EvaluateRes, Parameters, ndarrays_to_parameters, \    parameters_to_ndarrays# Configure logginglogging.basicConfig(    level=logging.INFO,    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',    handlers=[        logging.FileHandler("client_logs.log"),        logging.StreamHandler()    ])# Model definition - should be identical to the server modelclass NeuralNetwork(torch.nn.Module):    def __init__(self, input_dim=784, hidden_dim=128, output_dim=10):        super(NeuralNetwork, self).__init__()        self.layer_1 = torch.nn.Linear(input_dim, hidden_dim)        self.layer_2 = torch.nn.Linear(hidden_dim, hidden_dim)        self.layer_3 = torch.nn.Linear(hidden_dim, output_dim)        self.relu = torch.nn.ReLU()    def forward(self, x):        x = self.relu(self.layer_1(x))        x = self.relu(self.layer_2(x))        x = self.layer_3(x)        return xclass IoTClient(fl.client.NumPyClient):    def __init__(self, client_id: int, device: torch.device):        self.client_id = client_id        self.device = device        self.logger = logging.getLogger(f"Client-{client_id}")        # Initialize model        self.model = NeuralNetwork().to(device)        self.logger.info(f"Client {client_id} initialized with device: {device}")        # Setup dataset (to be customized for each client)        self.trainloader, self.testloader = self.load_data()        # Define loss function        self.criterion = torch.nn.CrossEntropyLoss()        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)    def load_data(self):        """        Load client-specific IoT dataset.        This method should be customized based on each client's data.        """        try:            # This is a placeholder. In a real scenario, each client would load their own data            self.logger.info(f"Client {self.client_id} loading dataset...")            # Simulated data loading for demonstration            # In a real scenario, you would load actual IoT device data here            # Example with sklearn for generating dummy data            from sklearn.datasets import make_classification            from torch.utils.data import TensorDataset, DataLoader            # Generate synthetic data specific to this client            X_train, y_train = make_classification(                n_samples=1000,                n_features=784,                n_classes=10,                n_informative=50,                random_state=self.client_id  # Use client_id as seed for different data            )            X_test, y_test = make_classification(                n_samples=200,                n_features=784,                n_classes=10,                n_informative=50,                random_state=self.client_id + 100            )            # Convert to PyTorch tensors            X_train_tensor = torch.FloatTensor(X_train)            y_train_tensor = torch.LongTensor(y_train)            X_test_tensor = torch.FloatTensor(X_test)            y_test_tensor = torch.LongTensor(y_test)            # Create data loaders            train_dataset = TensorDataset(X_train_tensor, y_train_tensor)            test_dataset = TensorDataset(X_test_tensor, y_test_tensor)            trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True)            testloader = DataLoader(test_dataset, batch_size=32)            self.logger.info(                f"Client {self.client_id} loaded {len(train_dataset)} training samples and {len(test_dataset)} test samples")            return trainloader, testloader        except Exception as e:            self.logger.error(f"Error loading data for client {self.client_id}: {e}")            raise    def get_parameters(self, config) -> List[np.ndarray]:        """Get model parameters as a list of NumPy arrays."""        self.logger.debug(f"Client {self.client_id} getting model parameters")        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]    def set_parameters(self, parameters: List[np.ndarray]) -> None:        """Set model parameters from a list of NumPy arrays."""        self.logger.debug(f"Client {self.client_id} setting model parameters")        params_dict = zip(self.model.state_dict().keys(), parameters)        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})        self.model.load_state_dict(state_dict, strict=True)    def fit(self, parameters: List[np.ndarray], config: Dict[str, str]) -> Tuple[List[np.ndarray], int, Dict]:        """Train the model on the local dataset."""        self.logger.info(f"Client {self.client_id} starting local training")        # Update local model with global parameters        self.set_parameters(parameters)        # Get training config from server        epochs = int(config.get("epochs", 1))        # Train the model        self.model.train()        for epoch in range(epochs):            running_loss = 0.0            correct = 0            total = 0            for batch_idx, (inputs, targets) in enumerate(self.trainloader):                inputs, targets = inputs.to(self.device), targets.to(self.device)                self.optimizer.zero_grad()                outputs = self.model(inputs)                loss = self.criterion(outputs, targets)                loss.backward()                self.optimizer.step()                # Compute metrics                running_loss += loss.item()                _, predicted = outputs.max(1)                total += targets.size(0)                correct += predicted.eq(targets).sum().item()            # Log epoch metrics            accuracy = correct / total            avg_loss = running_loss / len(self.trainloader)            self.logger.info(                f"Client {self.client_id} - Epoch {epoch + 1}/{epochs}: Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}")        # Return updated model parameters and metrics        final_accuracy = correct / total        return self.get_parameters(config={}), total, {"accuracy": float(final_accuracy), "loss": float(avg_loss)}    def evaluate(self, parameters: List[np.ndarray], config: Dict[str, str]) -> Tuple[float, int, Dict]:        """Evaluate the model on the local test dataset."""        self.logger.info(f"Client {self.client_id} evaluating model")        # Update local model with global parameters        self.set_parameters(parameters)        # Evaluate the model        self.model.eval()        loss = 0.0        correct = 0        total = 0        with torch.no_grad():            for inputs, targets in self.testloader:                inputs, targets = inputs.to(self.device), targets.to(self.device)                outputs = self.model(inputs)                batch_loss = self.criterion(outputs, targets).item()                loss += batch_loss                _, predicted = outputs.max(1)                total += targets.size(0)                correct += predicted.eq(targets).sum().item()        # Compute metrics        accuracy = correct / total        avg_loss = loss / len(self.testloader)        self.logger.info(f"Client {self.client_id} evaluation - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}")        return float(avg_loss), total, {"accuracy": float(accuracy)}def main():    # Parse command line arguments    parser = argparse.ArgumentParser(description="Flower IoT client")    parser.add_argument("--client-id", type=int, required=True, help="Client ID")    parser.add_argument("--server-address", type=str, default="127.0.0.1:8080", help="Server address")    args = parser.parse_args()    # Set device    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")    logger = logging.getLogger(f"Client-{args.client_id}")    logger.info(f"Using device: {device}")    # Create client    client = IoTClient(client_id=args.client_id, device=device)    # Start client    logger.info(f"Client {args.client_id} connecting to server at {args.server_address}")    fl.client.start_numpy_client(server_address=args.server_address, client=client)if __name__ == "__main__":    main()